# Emotion-Aware Virtual Classroom System

A comprehensive multimodal emotion recognition system for virtual learning environments with integrated video conferencing capabilities similar to Zoom.

## ğŸ¯ Project Overview

This system combines advanced emotion recognition technologies with virtual classroom functionality to create an intelligent learning environment that monitors student engagement and provides real-time insights to instructors.

### Key Features

- **Multimodal Emotion Recognition**: Facial expressions, audio emotions, and text sentiment analysis
- **Virtual Classroom**: WebRTC-based video conferencing with Zoom-like functionality  
- **Real-time Analytics**: Live dashboard for instructors with emotion monitoring
- **Privacy Compliance**: GDPR-compliant consent system and data encryption
- **Scalable Deployment**: Docker/Kubernetes ready for 100+ concurrent students
- **Advanced Reports**: PDF/Excel export with comprehensive analytics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Virtual        â”‚   Instructor    â”‚    Reports      â”‚   â”‚
â”‚  â”‚  Classroom      â”‚   Dashboard     â”‚    & Analytics  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                         WebSocket/HTTP
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (FastAPI)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   WebRTC API    â”‚  Emotion API    â”‚   Reports API   â”‚   â”‚
â”‚  â”‚   Auth & Securityâ”‚  Dashboard API  â”‚   Privacy API   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                          ML Processing
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ML Modules (PyTorch)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Facial CNN    â”‚   Audio MFCC    â”‚ Text Sentiment  â”‚   â”‚
â”‚  â”‚   (FER-2013)    â”‚   (RAVDESS)     â”‚ (HuggingFace)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    Multimodal Fusion                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        Data Storage
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Database & Storage (PostgreSQL + Redis)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 16+
- Docker & Docker Compose (for deployment)
- Kubernetes (optional, for production)

### Development Setup

1. **Clone and Install**
```bash
git clone <repository-url>
cd emotion-aware-classroom
pip install -r requirements_complete.txt
cd frontend && npm install
```

2. **Start Backend**
```bash
python backend/main.py
```

3. **Start Frontend**
```bash
cd frontend && npm start
```

4. **Access Applications**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

### Production Deployment

1. **Docker Deployment**
```bash
docker-compose up -d
```

2. **Kubernetes Deployment**
```bash
./deployment/deploy.sh
```

## ğŸ“š System Components

### Week 1-2: Core Setup & Facial Recognition
- âœ… Framework setup (PyTorch, FastAPI, React)
- âœ… WebRTC pipeline for video/audio capture
- âœ… Consent system for privacy compliance
- âœ… CNN model for facial emotion recognition (FER-2013 dataset)
- âœ… Real-time face detection with OpenCV

### Week 3-4: Audio & Text Analysis
- âœ… Audio emotion classifier using RAVDESS/IEMOCAP datasets
- âœ… MFCC feature extraction with Librosa
- âœ… HuggingFace transformer integration for text sentiment
- âœ… Live chat sentiment analysis API

### Week 5-6: Fusion & Dashboard
- âœ… Multimodal fusion system combining face/audio/text
- âœ… Learning state mapping (engaged, confused, bored, frustrated, curious, neutral)
- âœ… Real-time instructor dashboard with emotion monitoring
- âœ… WebSocket integration for live updates

### Week 7-8: Reports & Security
- âœ… Advanced visualization with charts and time-series analysis
- âœ… PDF/Excel report generation with comprehensive analytics
- âœ… JWT authentication and role-based access control
- âœ… Stream encryption and privacy compliance (GDPR)

### Week 9-10: Deployment & Testing
- âœ… Docker containerization with production configuration
- âœ… Kubernetes orchestration with auto-scaling
- âœ… Comprehensive stress testing for 100+ concurrent students
- âœ… Monitoring with Prometheus and Grafana

### Virtual Classroom Integration
- âœ… WebRTC-based video conferencing (Zoom-like functionality)
- âœ… Real-time chat and screen sharing
- âœ… Hand raising and participant management
- âœ… Integrated emotion monitoring during video calls
- âœ… Host controls for managing participants

## ğŸ¥ Virtual Classroom Features

### For Students
- **Video Conferencing**: Join classroom with camera and microphone
- **Screen Sharing**: Share screen for presentations
- **Chat**: Real-time text chat with other participants  
- **Hand Raising**: Virtual hand raising for questions
- **Emotion Detection**: Automatic emotion recognition during class
- **Privacy Controls**: Enable/disable video and audio as needed

### For Instructors  
- **Host Controls**: Manage participant permissions and settings
- **Real-time Monitoring**: Live emotion analytics of all students
- **Recording**: Record classroom sessions (when consented)
- **Alerts**: Get notified of student confusion or disengagement
- **Reports**: Post-class analytics and engagement reports

### Technical Implementation
- **WebRTC**: Peer-to-peer video/audio streaming
- **WebSocket**: Real-time signaling and messaging
- **Emotion Integration**: Live emotion data overlaid on video feeds
- **Scalable Architecture**: Supports 100+ concurrent participants

## ğŸ“Š Emotion Recognition Pipeline

### Input Modalities
1. **Facial Expressions**: Live video stream analysis
2. **Audio Emotions**: Microphone input processing  
3. **Text Sentiment**: Chat message analysis

### Processing Pipeline
1. **Real-time Capture**: WebRTC streams capture video/audio
2. **Feature Extraction**: CNN features, MFCC coefficients, text embeddings
3. **Model Inference**: Trained models predict emotions per modality
4. **Multimodal Fusion**: Combine predictions using weighted averaging
5. **Learning State Mapping**: Map to educational states (engaged, confused, etc.)
6. **Dashboard Update**: Real-time visualization for instructors

### Supported Emotions
- **Engagement**: Active participation and focus
- **Confusion**: Difficulty understanding material
- **Boredom**: Lack of interest or attention
- **Frustration**: Struggling with concepts
- **Curiosity**: Interest in learning more
- **Neutral**: Baseline emotional state

## ğŸ”§ API Documentation

### Virtual Classroom Endpoints

#### Room Management
- `POST /api/classroom/create-room` - Create new classroom
- `GET /api/classroom/rooms` - List available rooms
- `GET /api/classroom/room/{room_id}` - Get room details
- `DELETE /api/classroom/room/{room_id}` - Delete room (host only)

#### Real-time Communication
- `WebSocket /api/classroom/ws/{room_id}` - Join classroom WebSocket
- `GET /api/classroom/join/{room_id}` - Classroom web interface

#### Message Types (WebSocket)
- `webrtc_offer/answer/ice_candidate` - WebRTC signaling
- `chat_message` - Text chat
- `media_state_change` - Video/audio toggle
- `emotion_update` - Live emotion data
- `raise_hand` - Hand raising
- `host_control` - Instructor controls

### Emotion Recognition Endpoints
- `POST /api/v1/emotion/analyze` - Analyze emotion from image/audio/text
- `WebSocket /api/v1/emotion/stream` - Real-time emotion streaming
- `GET /api/v1/emotion/history` - Historical emotion data

### Dashboard & Reports
- `WebSocket /api/dashboard/ws/dashboard/{class_id}` - Real-time dashboard
- `GET /api/reports/api/class/{class_id}/analytics` - Analytics overview
- `GET /api/reports/api/class/{class_id}/export/pdf` - PDF report
- `GET /api/reports/api/class/{class_id}/export/excel` - Excel export

## ğŸ›¡ï¸ Security & Privacy

### Authentication
- JWT-based authentication with refresh tokens
- Role-based access control (instructor/student/admin)
- Password strength validation and rate limiting

### Privacy Compliance
- GDPR-compliant consent management
- Data anonymization and retention policies
- Encrypted data transmission (TLS 1.3)
- Stream encryption using AES-256-CBC

### Data Protection
- No permanent storage of video/audio streams
- Emotion data aggregation and anonymization  
- User consent required for all data collection
- Right to data deletion and export

## ğŸ“ˆ Performance & Scalability

### System Capacity
- **Concurrent Students**: 100+ per classroom
- **Response Time**: <2 seconds average for emotion analysis
- **Uptime**: 99.9% availability target
- **Throughput**: 1000+ emotion updates per minute

### Scaling Configuration
- **Horizontal Pod Autoscaler**: CPU/memory based scaling
- **Load Balancing**: Nginx with multiple backend replicas
- **Database**: PostgreSQL with connection pooling
- **Cache**: Redis for session management and real-time data

### Monitoring
- **Prometheus**: Metrics collection and alerting
- **Grafana**: Real-time dashboards and visualization
- **Health Checks**: Automated service monitoring
- **Log Aggregation**: Centralized logging for debugging

## ğŸ§ª Testing

### Automated Testing
```bash
# Week 1-8 Individual Tests
python test_week1_setup.py
python test_week2_facial.py
python test_week3_audio.py
python test_week4_text.py
python test_week5_fusion.py
python test_week6_dashboard.py
python test_week7_reports.py
python test_week8_security.py

# Comprehensive Stress Testing
python test_week10_stress.py
```

### Manual Testing
- Virtual classroom functionality with multiple participants
- Emotion recognition accuracy across different conditions
- Dashboard real-time updates and alerts
- Report generation and export features

## ğŸ“ Project Structure

```
emotion-aware-classroom/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ api/                   # API routes and endpoints
â”‚   â”œâ”€â”€ core/                  # Configuration and database
â”‚   â”œâ”€â”€ security/              # Authentication and encryption
â”‚   â””â”€â”€ main.py               # Application entry point
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/           # Main application pages
â”‚   â”‚   â”œâ”€â”€ services/        # API service layers
â”‚   â”‚   â””â”€â”€ store/           # Redux state management
â”œâ”€â”€ ml_modules/               # Machine learning components
â”‚   â”œâ”€â”€ facial_emotion/      # CNN for facial recognition
â”‚   â”œâ”€â”€ audio_emotion/       # Audio emotion classifier
â”‚   â”œâ”€â”€ text_sentiment/      # Text sentiment analysis
â”‚   â””â”€â”€ fusion/              # Multimodal fusion system
â”œâ”€â”€ deployment/              # Deployment configuration
â”‚   â”œâ”€â”€ docker/             # Docker configurations
â”‚   â”œâ”€â”€ kubernetes/         # Kubernetes manifests
â”‚   â””â”€â”€ deploy.sh          # Deployment scripts
â””â”€â”€ docs/                   # Documentation and diagrams
```

## ğŸ¤ Contributing

1. Follow the established code structure and patterns
2. Add comprehensive tests for new features
3. Update documentation for API changes
4. Ensure privacy compliance for any data handling
5. Test scalability impact for new features

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Datasets**: FER-2013, RAVDESS, IEMOCAP for training emotion models
- **Frameworks**: FastAPI, React, PyTorch for core functionality
- **WebRTC**: For real-time video conferencing capabilities
- **Security**: JWT and encryption libraries for data protection

---

**ğŸ‰ The Emotion-Aware Virtual Classroom is now complete with full virtual conferencing capabilities!**

For support and questions, please refer to the API documentation at `/docs` endpoint.